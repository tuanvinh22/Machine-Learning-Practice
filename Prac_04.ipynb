{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prac_04",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo_jx6FSyooS"
      },
      "source": [
        "We will do some experiments on the *Pima Indians Diabetes Dataset*. \n",
        "Download this dataset from this link: [\n",
        "Pima Indians Diabetes Dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database).\n",
        "\n",
        "**Dataset description:**\n",
        "The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on. \n",
        "\n",
        "*Can you build a machine learning model to accurately predict whether or not the patients in the dataset have diabetes or not?*\n",
        "\n",
        "---\n",
        "\n",
        "Run the following cell to download the dataset, or upload the `diabetes.csv` file to this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ybUC6V0yooT"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "from numpy.linalg import norm as L2Norm\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5asz3JNRSCl"
      },
      "source": [
        "Using Pandas, let's read the file and save all features are saved into matrix `X`, and the response values are saved into vector `y`. Print the first 5 rows of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8-_HfNHN5Kh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a5aac66b-f2f2-4e33-e6ae-33d7b2a22d0f"
      },
      "source": [
        "#TYPE YOUR ANSWER HERE\n",
        "df = pd.read_csv(\"diabetes.csv\");\n",
        "\n",
        "X = np.array(df.iloc[:, :-1])\n",
        "y = np.array(df.iloc[:, -1])\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 8) (768,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2bfcdc77-79aa-4905-b80f-6da01bc6fc47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bfcdc77-79aa-4905-b80f-6da01bc6fc47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2bfcdc77-79aa-4905-b80f-6da01bc6fc47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2bfcdc77-79aa-4905-b80f-6da01bc6fc47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdB8UexucBJI"
      },
      "source": [
        "## Section 0: Dataset Normalization\n",
        "In machine learning problems, we usually prefer working with *normalized* data, meaning that all input features should have the same scale (mean 0 and variance 1). This will speed up the the optimization process and increase the numerical stability, etc.\n",
        "\n",
        "$$\n",
        "\\textbf{x}_{normalized} = \\frac{\\textbf{x} - \\bar{\\textbf{x}}}{\\sigma_{\\textbf{x}}}\n",
        "$$\n",
        "where $\\bar{\\textbf{x}}$ and $\\sigma_{\\textbf{x}}$ are the mean and standard deviation of $\\textbf{x}$, respectively.\n",
        "\n",
        "---\n",
        "\n",
        "With the given features matrix `X`, implement the `normalize_features(X)` function by subtracting the *mean* of each feature (column of `X`) and dividing by its standard deviation. The provided function `np.mean()` and `np.std()` might be useful. Becareful with the `axis`! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TgAMTKVbPJY"
      },
      "source": [
        "def normalize_features(X):\n",
        "  #TYPE YOUR ANSWER HERE\n",
        "  K = np.linalg.inv(np.diag(np.std(X, axis = 0)))\n",
        "  return np.dot((X - np.mean(X, axis = 0)),K)\n",
        "\n",
        "## Just for clarification, we cannot divide matrix by matrix. Infact, in terms of matrices, the X_bar = np.dot((X-mean), K)\n",
        "## Where K is the inverse of the diagonal matrix of std components. Which means that Kij = 1/std(Xj), where (i,j) = (1,1), (2,2),...(n,n)\n",
        "## and j is the feature(column) number of X.\n",
        "\n",
        "## However, in Numpy, we can still write in an alternative way that X_bar = (X-X_mean)/STD\n",
        "## Where STD = np.std(X, axis = 0) with dimension of (1, number of features). Numpy will transform 1/STD into the K matrix as mentioned above.\n",
        "## Below is the test for that\n",
        "\n",
        "\n",
        "X_norm = normalize_features(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1SG_HDc0DPW",
        "outputId": "84cc762d-ccc5-44fc-be9c-5ffdc1646827"
      },
      "source": [
        "### [extra]\n",
        "X_norm1=(X - np.mean(X, axis = 0))/np.std(X, axis=0)\n",
        "print(f\"Here is X_norm {X_norm}\\n\\n\")\n",
        "print(f\"Here is X_norm1 {X_norm1}\\n\")\n",
        "\n",
        "### The result is that X_norm = X_norm1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is X_norm [[ 0.63994726  0.84832379  0.14964075 ...  0.20401277  0.46849198\n",
            "   1.4259954 ]\n",
            " [-0.84488505 -1.12339636 -0.16054575 ... -0.68442195 -0.36506078\n",
            "  -0.19067191]\n",
            " [ 1.23388019  1.94372388 -0.26394125 ... -1.10325546  0.60439732\n",
            "  -0.10558415]\n",
            " ...\n",
            " [ 0.3429808   0.00330087  0.14964075 ... -0.73518964 -0.68519336\n",
            "  -0.27575966]\n",
            " [-0.84488505  0.1597866  -0.47073225 ... -0.24020459 -0.37110101\n",
            "   1.17073215]\n",
            " [-0.84488505 -0.8730192   0.04624525 ... -0.20212881 -0.47378505\n",
            "  -0.87137393]]\n",
            "\n",
            "\n",
            "Here is X_norm1 [[ 0.63994726  0.84832379  0.14964075 ...  0.20401277  0.46849198\n",
            "   1.4259954 ]\n",
            " [-0.84488505 -1.12339636 -0.16054575 ... -0.68442195 -0.36506078\n",
            "  -0.19067191]\n",
            " [ 1.23388019  1.94372388 -0.26394125 ... -1.10325546  0.60439732\n",
            "  -0.10558415]\n",
            " ...\n",
            " [ 0.3429808   0.00330087  0.14964075 ... -0.73518964 -0.68519336\n",
            "  -0.27575966]\n",
            " [-0.84488505  0.1597866  -0.47073225 ... -0.24020459 -0.37110101\n",
            "   1.17073215]\n",
            " [-0.84488505 -0.8730192   0.04624525 ... -0.20212881 -0.47378505\n",
            "  -0.87137393]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62PJUbTUyooT"
      },
      "source": [
        "## Section I: Logistic Regression with SKLearn \n",
        "Using the `sklearn` to do logistic regression. What are the coefficients and the bias of your model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvTmYi5TyooT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c30ef7b-e355-4c31-d821-7af99cabd1f6"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#TYPE YOUR ANSWER HERE\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm,y, test_size = 0.2)\n",
        "\n",
        "lr = LR(max_iter=100000)\n",
        "lr.fit(X_train,y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "print('Mean squared error           :', sklearn.metrics.mean_squared_error(y_test, y_pred))\n",
        "print(\"Coefficient        : \",lr.coef_)\n",
        "print(\"Intercept (or bias):\", lr.intercept_)\n",
        "print(\"Accuracy: \", sklearn.metrics.accuracy_score(y_test.ravel(), y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error           : 0.21428571428571427\n",
            "Coefficient        :  [[ 0.50677685  1.05981319 -0.27457329  0.11708987 -0.1843684   0.66829459\n",
            "   0.32494546  0.10421091]]\n",
            "Intercept (or bias): [-0.91521047]\n",
            "Accuracy:  0.7857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CYG5vkhNDgD"
      },
      "source": [
        "##Section II: Logistic Regression with Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxcPa0LJRxGR"
      },
      "source": [
        "#PROVIDED CODE, RUN THIS CELL! \n",
        "def print_result(logs, w):\n",
        "  print(\"[Gradient Descent] Coefficients (alpha): \",\" \".join([\"{:.05f}\".format(i) for i in w[:-1]]))\n",
        "  print(\"[Gradient Descent] Bias (beta): \", w[-1])\n",
        "  plt.figure(figsize=(10,3))\n",
        "  plt.plot(logs[\"grad_f_vals\"], label = \"||grad_L(w)||\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Iterations\", size=15)\n",
        "  plt.ylabel(\"||grad_L(w)||\", size=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umRchNpme4ar"
      },
      "source": [
        "**Step 1:** Implement the Sigmoid Function\n",
        "$$S(\\textbf{z}) = \\frac{1}{1+e^{-\\textbf{z}}}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ef1stGyfSfu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d65555eb-0fd0-4b01-832e-766e23bd18cb"
      },
      "source": [
        "def sigmoid(z):\n",
        "  #TYPE YOUR ANSWER HERE\n",
        "  return 1/(1+np.exp(-z))\n",
        "\n",
        "#Visualization of Sigmoid Function\n",
        "x_sig = np.linspace(-10,10)\n",
        "y_sig = sigmoid(x_sig)\n",
        "plt.plot(x_sig,y_sig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1e07604d90>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpJFdawIu24t"
      },
      "source": [
        "**Step 2**:\n",
        "Recall from the previous lab assignment, you learned how to solve linear regression with gradient descent. Now, let's do the same for logistic regression. Using the simoid function in the previous part, you will need to implement: \n",
        "\n",
        "* The loss function `L(X,y,w)`\n",
        "* Gradient of the loss function `grad_L(X,y,w)`\n",
        "* Update rule for the weight, with a given gradient and learning rate\n",
        "\n",
        "---\n",
        "\n",
        "**LOGISTIC REGRESSION WITH GRADIENT DESCENT**\n",
        "\n",
        "With $\\bar{\\textbf{X}}$ is the augmented version of $\\textbf{X}$ by stacking an all ones column to the end.\n",
        "$$\n",
        "J(\\mathbf{w}) = -\\frac{1}{N}\\sum_{i=1}^n \\left[\\textbf{y}_i \\log \\textbf{z}_i + (1-\\textbf{y}_i) \\log (1 - \\textbf{z}_i)\\right]\n",
        "$$\n",
        "$$\n",
        "    \\nabla J(\\textbf{w}) = \\frac{1}{N} \\sum_{i=1}^n \\left[(\\textbf{z}_i - \\textbf{y}_i) \\bar{\\textbf{x}}_i \\right]\n",
        "$$\n",
        "where $\\textbf{z} = S(\\bar{\\textbf{X}}\\textbf{w})$.\n",
        "\n",
        "Gradient descent with fixed learning rate $\\delta$:\n",
        "$$\n",
        "\\textbf{w}_{k+1} = \\textbf{w}_{k} - \\delta.\\nabla J(\\textbf{w}_{k})\n",
        "$$\n",
        "Stopping criteria:\n",
        "$$\n",
        "  ||\\nabla L(\\textbf{w}_{k})||_2 < \\epsilon\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "Hint: The notation subscript $i$ here is just the $i^{th}$ element of a vector. Try to vectorize all the equations as much as you can. Summing across all training samples and divide by its total number is equivalent to calculate the mean in the first dimension (axis 0). Becareful with the shape of ($\\textbf{z}$ - $\\textbf{y}$) when subtracting, you might need to add an extra dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBq1GwpwH4R4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "24780989-02b7-40cc-d770-9a513bd39c9d"
      },
      "source": [
        "def L(X,y,w):\n",
        "    #TYPE YOUR ANSWER HERE\n",
        "    N = X.shape[0]\n",
        "    J_1 = np.dot(y.T, np.log(sigmoid(np.dot(X,w))))\n",
        "    J_2 = np.dot((1-y).T, np.log(1-sigmoid(np.dot(X,w))))\n",
        "    J = -1/N * (J_1 + J_2 )\n",
        "    return J\n",
        "\n",
        "def grad_L(X,y,w):\n",
        "    #TYPE YOUR ANSWER HERE\n",
        "    N = X.shape[0]\n",
        "    grad_J = 1/N *np.dot(X.T, (sigmoid(np.dot(X, w)) - y))\n",
        "    return grad_J\n",
        "\n",
        "\n",
        "def gradient_descent(func, grad_func, X, y, w0, lr = 1e-1, eps = 1e-6, max_iter = 10000):\n",
        "    \"\"\"\n",
        "    Runs gradient descent with a given loss function\n",
        "    :param func(X,y,w): the loss function that you want to optimize, with given input X, label y and weight w\n",
        "    :param grad_func(X,y,w): the gradient of the loss function\n",
        "    :param X: training set\n",
        "    :param y: label of the training set\n",
        "    :param w0: initial weight\n",
        "    :param lr: learning rate (fixed during training)\n",
        "    :param eps: epsilon for the stopping criteria\n",
        "    :param max_iters: the maximum number of iterations\n",
        "    :return: logs of each step (list of dictionary), and the best weight w \n",
        "    \"\"\"\n",
        "    k = 1\n",
        "    f_vals = []\n",
        "    grad_f_vals = []\n",
        "    w_hist = []\n",
        "    logs   = {}\n",
        "    w = w0.copy()\n",
        "    while True:\n",
        "        grad_f_k = grad_func(X, y, w) #gradient at step k\n",
        "        #Stoping criteria\n",
        "        if (L2Norm(grad_f_k) < eps) or (k > max_iter):\n",
        "            return  {\"f_vals\": np.array(f_vals), \n",
        "                     \"grad_f_vals\": np.array(grad_f_vals), \n",
        "                     \"w_hist\": np.concatenate([w0] + w_hist, axis = -1)}, w.flatten()\n",
        "        \n",
        "        #Update params:\n",
        "        \n",
        "        w = w - lr*grad_f_k #TYPE YOUR ANSWER HERE \n",
        "        \n",
        "        #Save logs\n",
        "        f_vals.append(func(X,y,w))\n",
        "        grad_f_vals.append(L2Norm(grad_f_k))\n",
        "        w_hist.append(w)\n",
        "        k+=1\n",
        "\n",
        "#Normalize\n",
        "X_bar = np.hstack([X_norm, np.ones((len(X),1))])   \n",
        "y = y.reshape((-1,1))\n",
        "\n",
        "print(X_bar.shape, y.shape)\n",
        "#Weight initialization\n",
        "w0 = np.random.rand(X.shape[1]+1).reshape((-1,1))\n",
        "print(w0.shape)\n",
        "#Run gradient descent\n",
        "logs, w = gradient_descent(L, grad_L, X_bar, y, w0, lr = 0.01, max_iter = 10000)\n",
        "#Print Result\n",
        "print_result(logs,w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9) (768, 1)\n",
            "(9, 1)\n",
            "[Gradient Descent] Coefficients (alpha):  0.41466 1.12274 -0.25691 0.00923 -0.13656 0.70687 0.31290 0.17486\n",
            "[Gradient Descent] Bias (beta):  -0.8709518921034783\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHcY5MZyioDp",
        "outputId": "95441898-4a6d-4474-9c33-d409d49cc2cb"
      },
      "source": [
        "### Check accuracy:\n",
        "\n",
        "y_pred = sigmoid(np.dot(X_test,w[:-1]) + w[-1])\n",
        "\n",
        "###\n",
        "y_pred[y_pred > 0.5] = 1\n",
        "y_pred[y_pred <= 0.5] = 0\n",
        "###\n",
        "\n",
        "y_pred_norm = sigmoid(np.dot(X_norm,w[:-1]) + w[-1])\n",
        "y_pred_norm[y_pred_norm > 0.5] = 1\n",
        "y_pred_norm[y_pred_norm <= 0.5] = 0\n",
        "\n",
        "print(\"Accuracy on test set:\", sklearn.metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Accuracy on the whole dataset\", sklearn.metrics.accuracy_score(y, y_pred_norm))\n",
        "### Look at the result, we can see that it's nearly the same with when we use sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 0.7857142857142857\n",
            "Accuracy on the whole dataset 0.7825520833333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8iTeZP3n-d6"
      },
      "source": [
        "Recall that you subtracted the mean and divided by the standard deviation of the input features, so the mode (coefficients and bias) you learned can only work on this *normalized* dataset. Now if you want to do switch back to the original one, how can you transform this learned weight into the one that can work on non-normalized dataset? Implement this function if you can. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1CWAiZBj2qN"
      },
      "source": [
        "#TYPE YOUR ANSWER HERE\n",
        "def denormalize(X, w_norm):\n",
        "  K = np.linalg.pinv(X - np.mean(X, axis = 0))\n",
        "  W_denorm = np.dot(K, np.dot(X_norm,w[:-1]) + w[-1] - w_norm[-1])\n",
        "\n",
        "  B = w_norm[-1] - np.dot(np.mean(X, axis = 0), W_denorm)\n",
        "  return W_denorm, B\n",
        "\n",
        "W, B = denormalize(X, w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFUAT3pi4sH5",
        "outputId": "fa41842c-e6e4-4142-9f05-33629f3c724b"
      },
      "source": [
        "### If denormalize successfully, then the accuracy of 2 prediction must be the same!!!!\n",
        "### Test below:\n",
        "\n",
        "y_pred_norm = sigmoid(np.dot(X_norm,w[:-1]) + w[-1])\n",
        "y_pred_norm[y_pred_norm > 0.5] = 1\n",
        "y_pred_norm[y_pred_norm <= 0.5] = 0\n",
        "\n",
        "\n",
        "print(\"Accuracy of normalized prediction:\", sklearn.metrics.accuracy_score(y, y_pred_norm))\n",
        "\n",
        "####\n",
        "y_pred_denorm = sigmoid(np.dot(X,W) + B)\n",
        "y_pred_denorm[y_pred_denorm > 0.5] = 1\n",
        "y_pred_denorm[y_pred_denorm <= 0.5] = 0\n",
        "\n",
        "print(\"Accuracy of denormalized prediction:\", sklearn.metrics.accuracy_score(y, y_pred_denorm))\n",
        "\n",
        "print(\"Compare between normalized and denormalized predictions:\", sklearn.metrics.accuracy_score(y_pred_norm, y_pred_denorm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of normalized prediction: 0.7825520833333334\n",
            "Accuracy of denormalized prediction: 0.7825520833333334\n",
            "Compare between normalized and denormalized predictions: 1.0\n"
          ]
        }
      ]
    }
  ]
}